{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge: Estimating Costs of an LLM API\n",
        "\n",
        "LLM API token costs can vary depending on the complexity of your prompts and how your users interact with your application. In this challenge, you will have to measure the cost of our API usage.\n",
        "\n",
        "As a bonus you can see how using more complex prompting techniques from few shot prompting to chain-of-thought prompting increases the cost.\n",
        "\n",
        "[![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LinkedInLearning/generative-ai-and-llmops-deploying-and-managing-llms-in-production-4465782/blob/main/ch-06/challenge_estimating_API_costs.ipynb)"
      ],
      "metadata": {
        "id": "oCdOdNL8JSBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai -q"
      ],
      "metadata": {
        "id": "VLopcvd3Cl96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os"
      ],
      "metadata": {
        "id": "2_289xWjClMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Add your API key here\n",
        "client = OpenAI(api_key=\"<API-KEY-HERE>\")"
      ],
      "metadata": {
        "id": "cxmQQF9ICpQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Find the current cost for each input and output token\n",
        "input_token_cost =\n",
        "output_token_cost ="
      ],
      "metadata": {
        "id": "cGrZ63Ll1txH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRYZUQ9_uTEo"
      },
      "outputs": [],
      "source": [
        "def calculate_cost(input_tokens, output_tokens):\n",
        "    #TODO: Calculate the total cost based on input and output tokens\n",
        "\n",
        "def generate_text_and_calculate_cost(prompt, model=\"gpt-4-turbo\"):\n",
        "    # TODO: Write a function to prompt an OpenAI model.\n",
        "    # Then parse the response to get the number of input and output tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using tiktoken"
      ],
      "metadata": {
        "id": "-5Sd7dUJDqi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "UgSIDplFDqST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def calculate_cost(input_prompt, generated_output, model):\n",
        "    # TODO: Instead of calling OpenAI, use the tiktoken package to calculate the tokens and costs"
      ],
      "metadata": {
        "id": "pOoa-r4CDtTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "haexG56E3U-h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}