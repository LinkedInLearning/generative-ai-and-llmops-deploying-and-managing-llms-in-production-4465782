{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wHkktWPSNTH"
   },
   "source": [
    "# Challenge: API Limitations for LLM deployment\n",
    "\n",
    "In this challenge, you will have to query the Groq's LLM API. You will then need to calculate the latency and throughput of Groq's API.\n",
    "\n",
    "As a bonus, you can also compare the performance of Groq's API with OpenAI's API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LinkedInLearning/generative-ai-and-llmops-deploying-and-managing-llms-in-production-4465782/blob/main/ch-02/challenge_API_limitations.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0-Q5FXjfKHK"
   },
   "outputs": [],
   "source": [
    "# TODO Install the Groq Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9esvOP1ap8R"
   },
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import getpass\n",
    "\n",
    "# TODO: Create a Groq Client\n",
    "# You can get token from console.groq.com\n",
    "client = Groq(api_key=getpass.getpass())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMXH-N19gW23"
   },
   "outputs": [],
   "source": [
    "def generate_text():\n",
    "    # TODO: Write a function to query the Groq API with a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUGTqYWtgdI_"
   },
   "outputs": [],
   "source": [
    "# TODO: Calculate the Latency and Throughput of Groq's API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hLOlOqGka_U"
   },
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2DaHkXtsibge"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "client = OpenAI(api_key=getpass.getpass())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLoCH8zLmdRH"
   },
   "outputs": [],
   "source": [
    "# TODO: As a bonus, calculate and compare the latency and throughput of OpenAI's API with Groq's"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
